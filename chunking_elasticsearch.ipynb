{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20518,"status":"ok","timestamp":1722422513080,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"RnRyGKmoE994","outputId":"e707294b-4451-4bc6-8147-c0765ce1acb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1722422578512,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"LX-yFXkWE7_i"},"outputs":[],"source":["import os\n","#from dotenv import load_dotenv\n","\n","#load_dotenv(verbose=True)\n","ES_CLOUD_ID = 'f950ade65a814f45b5b8e877d966S1527:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGJmYzNmZDY4MjdiOTRhNGVhOGQ1NmY5ODA1YTQ0Y2FlJGNhYzk3NmUyZTMyMzQ0YjJhNTU3MTdjZTk4OTM5Mjhl'\n","ES_USER = '4177922518'\n","ES_PASSWORD = 'ghdtjrwn1!'\n","ES_API_KEY = 'RTVnOUFwRUJHY25xVFJJQWh6bVo6c0JYZm1keGRRblNaU25IM0pQdE56QQ=='\n","index_name = \"helloworld7\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2971,"status":"ok","timestamp":1722422581482,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"uiLicgzTRpKh"},"outputs":[],"source":["import torch\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import json\n","\n","CONFIG_NAME = \"config.json\"\n","with open(f'configs/{CONFIG_NAME}', 'r') as f:\n","    config = json.load(f)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# # Embeddings by llama.cpp quantized model\n","# # llama-cpp-python 설치 필요\n","# # from transformers import AutoTokenizer, AutoModelForCausalLM\n","# # from langchain_community.llms import LlamaCpp\n","# from typing import List\n","# from langchain_community.embeddings import LlamaCppEmbeddings\n","\n","# class BllossomEmbeddings:\n","#         def __init__(self):\n","#             self.model = LlamaCppEmbeddings(\n","#                 model_path=config['config']['quantized_path'],\n","#                 n_gpu_layers=-1,\n","#                 n_batch=config['config']['n_batch'],\n","#                 # callback_manager=callback_manager,\n","#                 # temperature=config['inference']['temperature'],\n","#                 # top_p=config['inference']['top_p'],\n","#                 # top_k=config['inference']['top_k'],\n","#                 # max_tokens=config['inference']['max_length'],\n","#                 verbose=True,  # Verbose is required to pass to the callback manager\n","#             )\n","\n","#         # AttributeError: 'LlamaCpp' object has no attribute 'encode'\n","#         def embed_documents(self, texts: List[str]) -> List[List[float]]:\n","#             return [self.model.encode(t).tolist() for t in texts]\n","        \n","#         def embed_query(self, query: str) -> List[float]:\n","#             return self.model.encode([query])\n","\n","\n","#         # def embed_documents(self, texts: List[str]) -> List[List[float]]:\n","#         #     return [self._get_embeddings(t) for t in texts]\n","        \n","#         # def embed_query(self, query: str) -> List[float]:\n","#         #     return self._get_embeddings(query)\n","        \n","#         # def _get_embeddings(self, text: str) -> List[float]:\n","#         #     output = self.model(text)\n","#         #     print('## output : ', output)\n","#         #     # Assuming output is a list of token embeddings, we average them to get a fixed-size embedding\n","#         #     # embeddings = np.mean(output, axis=0)\n","#         #     return output"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305,"referenced_widgets":["6ad9508fa2fa4085b95c2cca010099aa","ab5e89ebc4444135923950fac5468b62","ee36a15415484fb3b1e4bec940f92e08","9866d0f8c89f47bcb38206fbb6ae3829","3d07eaace9404d1bb7abeb529969385b","1b4037abe1fe4aa8b75bc11cb505c554","b8ea293833a14f8188ab448ce0587dcd","08f37f8a9f0143959f0c965b9c192c12","b742f7bc99814e42a1c4729770364ae5","81b3af1f90a543ce9f86926ce9da364b","688b3e75396b4a7c84a7966407b8e87c"]},"executionInfo":{"elapsed":159564,"status":"ok","timestamp":1722422741044,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"jfhQO1EHE7_l","outputId":"e2df9631-4ed3-4c2b-9476-60577811fb6a"},"outputs":[{"name":"stdout","output_type":"stream","text":[">> Prep. Llama-cpp Quantized embedding setup\n"]},{"name":"stderr","output_type":"stream","text":["llama_model_loader: loaded meta data with 32 key-value pairs and 291 tensors from bllossom/llama-3-Korean-Bllossom-8B-Q5_K_M.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Elo_Best_Chat_Model\n","llama_model_loader: - kv   3:                       general.organization str              = MLP KTLim\n","llama_model_loader: - kv   4:                         general.size_label str              = 8.0B\n","llama_model_loader: - kv   5:                            general.license str              = llama3\n","llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\n","llama_model_loader: - kv   7:                  general.base_model.0.name str              = Meta Llama 3 8B\n","llama_model_loader: - kv   8:          general.base_model.0.organization str              = Meta Llama\n","llama_model_loader: - kv   9:              general.base_model.0.repo_url str              = https://huggingface.co/meta-llama/Met...\n","llama_model_loader: - kv  10:                          general.languages arr[str,2]       = [\"en\", \"ko\"]\n","llama_model_loader: - kv  11:                          llama.block_count u32              = 32\n","llama_model_loader: - kv  12:                       llama.context_length u32              = 8192\n","llama_model_loader: - kv  13:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv  14:                  llama.feed_forward_length u32              = 14336\n","llama_model_loader: - kv  15:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv  16:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  17:                       llama.rope.freq_base f32              = 500000.000000\n","llama_model_loader: - kv  18:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  19:                          general.file_type u32              = 17\n","llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n","llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n","llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n","llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n","llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n","llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 128001\n","llama_model_loader: - kv  30:                    tokenizer.chat_template str              = {% if not add_generation_prompt is de...\n","llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q5_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","llm_load_vocab: special tokens cache size = 256\n","llm_load_vocab: token to piece cache size = 0.8000 MB\n","llm_load_print_meta: format           = GGUF V3 (latest)\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = BPE\n","llm_load_print_meta: n_vocab          = 128256\n","llm_load_print_meta: n_merges         = 280147\n","llm_load_print_meta: vocab_only       = 0\n","llm_load_print_meta: n_ctx_train      = 8192\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 8\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_swa            = 0\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 4\n","llm_load_print_meta: n_embd_k_gqa     = 1024\n","llm_load_print_meta: n_embd_v_gqa     = 1024\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: f_logit_scale    = 0.0e+00\n","llm_load_print_meta: n_ff             = 14336\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: causal attn      = 1\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 500000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_ctx_orig_yarn  = 8192\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 8B\n","llm_load_print_meta: model ftype      = Q5_K - Medium\n","llm_load_print_meta: model params     = 8.03 B\n","llm_load_print_meta: model size       = 5.33 GiB (5.70 BPW) \n","llm_load_print_meta: general.name     = Elo_Best_Chat_Model\n","llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n","llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n","llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n","llm_load_print_meta: LF token         = 128 'Ä'\n","llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n","llm_load_print_meta: max token length = 256\n","llm_load_tensors: ggml ctx size =    0.14 MiB\n","llm_load_tensors:        CPU buffer size =  5459.93 MiB\n",".........................................................................................\n","llama_new_context_with_model: n_ctx      = 2048\n","llama_new_context_with_model: n_batch    = 256\n","llama_new_context_with_model: n_ubatch   = 256\n","llama_new_context_with_model: flash_attn = 0\n","llama_new_context_with_model: freq_base  = 500000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n","llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n","llama_new_context_with_model:        CPU  output buffer size =     0.02 MiB\n","llama_new_context_with_model:        CPU compute buffer size =   129.25 MiB\n","llama_new_context_with_model: graph nodes  = 1030\n","llama_new_context_with_model: graph splits = 1\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n","Model metadata: {'tokenizer.chat_template': \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.padding_token_id': '128001', 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.vocab_size': '128256', 'general.file_type': '17', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.feed_forward_length': '14336', 'general.architecture': 'llama', 'llama.attention.head_count_kv': '8', 'llama.block_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Elo_Best_Chat_Model', 'llama.rope.dimension_count': '128', 'general.base_model.0.name': 'Meta Llama 3 8B', 'general.organization': 'MLP KTLim', 'general.type': 'model', 'general.size_label': '8.0B', 'general.base_model.0.repo_url': 'https://huggingface.co/meta-llama/Meta-Llama-3-8B', 'general.license': 'llama3', 'general.base_model.count': '1', 'general.base_model.0.organization': 'Meta Llama', 'llama.embedding_length': '4096'}\n","Available chat formats from metadata: chat_template.default\n","Using gguf chat template: {% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n","\n","'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n","\n","' }}{% endif %}\n","Using chat eos_token: <|eot_id|>\n","Using chat bos_token: <|begin_of_text|>\n"]}],"source":["# from langchain.embeddings import HuggingFaceEmbeddings\n","from typing import List\n","from langchain_community.embeddings import LlamaCppEmbeddings\n","\n","def setup_embeddings():\n","    # Huggingface embedding setup\n","    # print(\">> Prep. Huggingface embedding setup\")\n","    print(\">> Prep. Llama-cpp Quantized embedding setup\")\n","    embeddings = LlamaCppEmbeddings(\n","                model_path=config['config']['quantized_path'],\n","                n_gpu_layers=-1,\n","                n_batch=config['config']['n_batch'],\n","                n_ctx=config['config']['n_ctx'],\n","                # callback_manager=callback_manager,\n","                # temperature=config['inference']['temperature'],\n","                # top_p=config['inference']['top_p'],\n","                # top_k=config['inference']['top_k'],\n","                # max_tokens=config['inference']['max_length'],\n","    )\n","    return embeddings\n","    # return HuggingFaceEmbeddings(model_name=model_name, cache_folder=\"./cache\", model_kwargs={\"device\" : \"cuda:0\"})\n","\n","hf = setup_embeddings()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1722422741486,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"fc-qNnbnE7_m"},"outputs":[],"source":["# ElasticSearch vectorstore in langchain style\n","from langchain_elasticsearch import ElasticsearchStore\n","\n","db = ElasticsearchStore(\n","    es_cloud_id=ES_CLOUD_ID,\n","    es_user=ES_USER,\n","    es_password=ES_PASSWORD,\n","    es_api_key=ES_API_KEY,\n","    index_name=index_name,\n","    embedding=hf,\n","    #es_url = 'https://bfc3fd6827b94a4ea8d56f9805a44cae.us-central1.gcp.cloud.es.io:443'\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1722422741486,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"lMM-5AvQV36G","outputId":"96c5f5b5-7f6d-4c08-cff9-39e18dbedc4f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'helloworld7'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["index_name"]},{"cell_type":"markdown","metadata":{"id":"Iu-mJbaSE7_m"},"source":["### Data chunking"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":480,"status":"ok","timestamp":1722422741964,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"NHRNI8YZE7_o","outputId":"f8f76925-191b-4e66-e598-d50118b4a9ab"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-9ff354dc-0ee2-4ece-9bb3-dd4375978d3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>title</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>중도 퇴사 후 근로소득 신고되지 않아 고용허가연장 안된 노동자 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 여주시\\n국적: 우즈베키...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>국민연금 반환일시금 신청 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 기타\\n거주지역: 남양주시\\n국적: 필리핀\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>외국인아동 교육권 보장을 위한 체류자격 부여자(G-1-85) 외국인등록 절차 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 남양주시\\n국적: 필리핀...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>단체행동을 통해 체불임금 해결한 사례</td>\n","      <td>작성일: 23-11-27\\n상담유형: 임금체불\\n거주지역: 안산시\\n국적: 필리핀\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>취업가능기간이 짧게 남아 취업이 어려운 노동자 구직활동 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 고용허가\\n거주지역: 시흥시\\n국적: 필리핀\\...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","      \n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ff354dc-0ee2-4ece-9bb3-dd4375978d3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","      \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","    \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9ff354dc-0ee2-4ece-9bb3-dd4375978d3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9ff354dc-0ee2-4ece-9bb3-dd4375978d3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","  \n","    </div>\n","  </div>\n","  "],"text/plain":["            source                                          title  \\\n","0  경기도외국인지원센터_상담사례          중도 퇴사 후 근로소득 신고되지 않아 고용허가연장 안된 노동자 지원   \n","1  경기도외국인지원센터_상담사례                               국민연금 반환일시금 신청 지원   \n","2  경기도외국인지원센터_상담사례  외국인아동 교육권 보장을 위한 체류자격 부여자(G-1-85) 외국인등록 절차 지원   \n","3  경기도외국인지원센터_상담사례                           단체행동을 통해 체불임금 해결한 사례   \n","4  경기도외국인지원센터_상담사례              취업가능기간이 짧게 남아 취업이 어려운 노동자 구직활동 지원   \n","\n","                                             content  \n","0  작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 여주시\\n국적: 우즈베키...  \n","1  작성일: 23-11-27\\n상담유형: 기타\\n거주지역: 남양주시\\n국적: 필리핀\\n...  \n","2  작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 남양주시\\n국적: 필리핀...  \n","3  작성일: 23-11-27\\n상담유형: 임금체불\\n거주지역: 안산시\\n국적: 필리핀\\...  \n","4  작성일: 23-11-27\\n상담유형: 고용허가\\n거주지역: 시흥시\\n국적: 필리핀\\...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from tqdm import tqdm\n","\n","# 임시로 경로 변경\n","data = pd.read_csv('data/preprocessed.csv')\n","#data['text'] = ''\n","data.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1722422748445,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"KD0HNBMQE7_o","outputId":"de749cc4-3079-4309-d57e-52625c493ef7"},"outputs":[{"data":{"text/plain":["(3433, 3)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"F9iMKz_CE7_o"},"outputs":[],"source":["# from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# text_splitter = RecursiveCharacterTextSplitter(\n","#     chunk_size = 500,\n","#     chunk_overlap  = 100,\n","#     length_function = len,\n","# )\n","\n","# #texts = text_splitter.split_text(data[0].page_content)\n","# texts = text_splitter.split_text(data['content'][0])\n","# len(texts)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["aa8daaf8b869410f90c7bc6b30d277bf","e4baa9d7f32f4edeb2810c3f8ca662ec","296fbd2153004fb2910e4858a64691a2","8749e24a6ec04f15837df3eb16c9b8b2","3d158802a6204c1f862366f20640eeb5","e6dce1142b0b435285d74e01c9b159ee","30bf2d11a4aa41739e6b6509468bcf2a","1f4c3f16910c4d42ada44a9984dee543","1e2becfd6e7a444583135c3db89783cb","63fc1f84511647af934a8fd7f04bc1f2","4a5aad8ac915498e9ec69b142c5a6472","3a2b3e1241f243a1a521697b71685e75","034fa144d85841e788c5718dfec065c0","b823462c585d42da9ae802cd26a77712","64f987ab2e66463295ff5b902f9222c2","9c1cd57eaaa74ccc83eab30413e713c6","1762ddb7291144e998dbd1ed3c00c52b","79d909c5afbd42a0a6a7f0ba3568cfc7","b90ba20967694c4489633599b8a4d6a1","392e3eaac48444bea7af4ca24ac60a18","59814da888914dacab99a7b6c2f3bd6c","672a8952726d42918e6a8d375050f217","3815dd748a0d46239eab5f67988a398c","fd0cf5e997af433bbbe25c2bcc68848b","dcf2b444c8cf4653b75ff160d3e6bb50","1fd84ff3969941d085e4f5a3d59cde9a","bbefff3cbb274e89acfde2be1b3acdad","238cf22a9a744240ac3e9ad270ee68c0","2d13c432356d42fabfc0c1bfe1cb737c","13c7760b6ee3478bbb807af9d24daa09","2c659e2591e942419a7c026c7fde6dc7","480cbf11fde04f6f94e3dca974979dca","7011c6a9fa924c5689fd03f9144f5685"]},"executionInfo":{"elapsed":1873,"status":"ok","timestamp":1722422752519,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"X7BRQ7yQE7_p","outputId":"b92a5644-a412-43b6-a073-1aeebc92f0fe"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:99: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import AutoTokenizer\n","\n","# LLaMA-3 토크나이저 로드\n","tokenizer = AutoTokenizer.from_pretrained(\"MLP-KTLim/llama-3-Korean-Bllossom-8B\")"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":277,"status":"ok","timestamp":1722422760434,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"6BVxkn-zE7_p"},"outputs":[],"source":["from langchain.docstore.document import Document\n","# import pandas as pd\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_core.documents import Document\n","\n","# RAG style : title + [SEP] + contents\n","# seperation 지정되어 있지 않음 -> 공백으로 처리\n","def make_chunk_data(titles: list, contents: list) -> list:\n","    if tokenizer.sep_token != None:\n","        print('## seperated by : ', tokenizer.sep_token)\n","        chunk_data = [title + tokenizer.sep_token + content for title, content in zip(titles, contents)]\n","    else:\n","        chunk_data = [title + \" \" + content for title, content in zip(titles, contents)]\n","\n","    return chunk_data\n","\n","\n","# 토크나이저 기준 분할\n","def data_chunking(titles: list, contents: list, sources: list) -> Document:\n","    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n","        tokenizer,\n","        chunk_size=config['config']['chunk_size'],\n","        chunk_overlap=config['config']['overlap_size']\n","    )\n","    chunk_data = make_chunk_data(titles, contents)\n","    chunks = text_splitter.create_documents(chunk_data, sources)\n","\n","    return chunks"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1bbf79ca-30d2-4a52-88c3-1b2b373e9ebe\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>title</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>중도 퇴사 후 근로소득 신고되지 않아 고용허가연장 안된 노동자 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 여주시\\n국적: 우즈베키...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>국민연금 반환일시금 신청 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 기타\\n거주지역: 남양주시\\n국적: 필리핀\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>외국인아동 교육권 보장을 위한 체류자격 부여자(G-1-85) 외국인등록 절차 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 남양주시\\n국적: 필리핀...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>단체행동을 통해 체불임금 해결한 사례</td>\n","      <td>작성일: 23-11-27\\n상담유형: 임금체불\\n거주지역: 안산시\\n국적: 필리핀\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>경기도외국인지원센터_상담사례</td>\n","      <td>취업가능기간이 짧게 남아 취업이 어려운 노동자 구직활동 지원</td>\n","      <td>작성일: 23-11-27\\n상담유형: 고용허가\\n거주지역: 시흥시\\n국적: 필리핀\\...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","      \n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bbf79ca-30d2-4a52-88c3-1b2b373e9ebe')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","      \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","    \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1bbf79ca-30d2-4a52-88c3-1b2b373e9ebe button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1bbf79ca-30d2-4a52-88c3-1b2b373e9ebe');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","  \n","    </div>\n","  </div>\n","  "],"text/plain":["            source                                          title  \\\n","0  경기도외국인지원센터_상담사례          중도 퇴사 후 근로소득 신고되지 않아 고용허가연장 안된 노동자 지원   \n","1  경기도외국인지원센터_상담사례                               국민연금 반환일시금 신청 지원   \n","2  경기도외국인지원센터_상담사례  외국인아동 교육권 보장을 위한 체류자격 부여자(G-1-85) 외국인등록 절차 지원   \n","3  경기도외국인지원센터_상담사례                           단체행동을 통해 체불임금 해결한 사례   \n","4  경기도외국인지원센터_상담사례              취업가능기간이 짧게 남아 취업이 어려운 노동자 구직활동 지원   \n","\n","                                             content  \n","0  작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 여주시\\n국적: 우즈베키...  \n","1  작성일: 23-11-27\\n상담유형: 기타\\n거주지역: 남양주시\\n국적: 필리핀\\n...  \n","2  작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 남양주시\\n국적: 필리핀...  \n","3  작성일: 23-11-27\\n상담유형: 임금체불\\n거주지역: 안산시\\n국적: 필리핀\\...  \n","4  작성일: 23-11-27\\n상담유형: 고용허가\\n거주지역: 시흥시\\n국적: 필리핀\\...  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1722422802735,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"eQEzx-sFE7_p"},"outputs":[],"source":["from tqdm import tqdm\n","# 빈 리스트 초기화\n","titles = []\n","contents = []\n","sources = []\n","\n","# 데이터프레임 순회\n","for index, row in data.iterrows():\n","    titles.append(row['title'])\n","    contents.append(row['content'])\n","    sources.append({'source': row['source']})\n","\n","# 결과 확인\n","#print(\"Titles:\", titles)\n","#print(\"Contents:\", contents)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1722422810306,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"6mBPY--hE7_q","outputId":"9e54c7b4-189f-4c3d-efcc-7a93c789cb76"},"outputs":[{"data":{"text/plain":["(3433, 3433, 3433)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(titles), len(contents), len(sources)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":26807,"status":"ok","timestamp":1722422838221,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"dU3hRmZmE7_q"},"outputs":[],"source":["chunks = data_chunking(titles, contents, sources)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1722422841891,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"_6xEotR8E7_q","outputId":"f3e29ca7-d40a-4b94-b44f-767143c48ba1"},"outputs":[{"data":{"text/plain":["8360"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["len(chunks)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1722422853482,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"GyuGDMdjE7_r","outputId":"f62cfad6-f6a1-4594-d727-01a7b6b3a4ef"},"outputs":[{"data":{"text/plain":["[Document(metadata={'source': '경기도외국인지원센터_상담사례'}, page_content='중도 퇴사 후 근로소득 신고되지 않아 고용허가연장 안된 노동자 지원 작성일: 23-11-27\\n상담유형: 체류자격\\n거주지역: 여주시\\n국적: 우즈베키스탄\\n체류자격: E-9\\n상담내용: 중도 퇴직하는 외국인 근로자의 추가 납부세액 사례\\n진행 과정 및 결과: 2023-09-18\\n- 고용노동부에서 외국인근로자의 2020년 종합소득세 체납을   확인하여 고용허가제 연장 불가능 안내받았음 \\n 회사 담당자하고 여주세무서에 방문 및 체납된 세금의 원인 상담 내용을 통역 요청으로 전화 상담 \\n타행송금; 자동차세-7.360원, 2021년 주민세-11,330원, 2022년 주민세-11,330원, 2022년 지방세 44,630원, 2022년 소득세 – 476,590원, 2021년 지방세 173,140원, \\n공과금 2020년 1,808,950원 안내 통역함\\n\\n2020-09-20\\n- 2021년에 연말정산 신청하여 469,520원 환급받았음 \\n- 체류자격 연장을 위해서 합계 2,533,330원을 납부함 \\n공과금 납부 내용을 상담하러 이천세무서에 동시 통역 가능한지 문의로 전화 상담 \\n10월 21일 오전 10시에 이천세무서에 방문 예정 안내함'),\n"," Document(metadata={'source': '경기도외국인지원센터_상담사례'}, page_content='2023-09-21\\n- 이천세무서 3층 소득세과에 방문 상담 내용 통번역 함\\n- 1,808,000원 2020년도의 체납 안내: \\n외국인근로자의 2020년에 중도에 퇴직후에 근로소득 신고하지 않아서 추가 체납 확인 \\n* 근로자가 중도에 퇴직하는 경우 원천징수의무자(회사)는 퇴직하는 달의 근로소득을 지급하는 때에 근로소득 세액을 징수함.\\n * 따라서, 중도 퇴직하는 근로자의 경우 퇴직하는 달의 급여를 받기 전 회사에 근로소득자의 소득·세액공제신고서와 증빙서류를 제출하여야 함  \\n* 관련 법령: 소득세법 제137조 내용 안내 통역 \\n\\n2023-09-27\\n - 체류지원 문의로 전화 상담 \\n- 고용허가제 연장 확인함 \\n- 11월 22일에 출입국사무소 방문예약함 \\n- 외국인등록증은 10월 16일 만료 예정 \\n- 회사 담당자가 바쁘셔서 출입국사무소에 방문 예약 기간에 갈 수 있다고 함 \\n- 출입국사무소에 10월 16일 이후에 방문하면 문제가 생기지 않는지 문의로 전화\\n*문의에 대한 답\\n- 외국인노동자는 고용허가 받은 후에 출입국사무소에서도 인정함 안내\\n- 고용허가 발급 후에 고용주 없이 외국인노동자는 출입국사무소에 방문 가능 안내\\n민원실에서 내담자가 신청 중임 확인 안내 통번역 완료')]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["chunks[0:2]"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1722422865668,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"a35CZkUXZyoA","outputId":"2c6b7eed-484d-48d7-de31-450db19ef901"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'helloworld7'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["index_name"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1545865,"status":"ok","timestamp":1722424413088,"user":{"displayName":"황예원","userId":"00995447241817203628"},"user_tz":-540},"id":"AzrpvWN2E7_r","outputId":"0302ab5d-6067-4ebc-f15a-6a6e8defa9d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26748.72 ms /   256 tokens (  104.49 ms per token,     9.57 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26825.13 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26437.89 ms /   256 tokens (  103.27 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26531.85 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26230.91 ms /   256 tokens (  102.46 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26310.99 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26316.79 ms /   256 tokens (  102.80 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26395.92 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    2936.11 ms /    31 tokens (   94.71 ms per token,    10.56 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    2979.91 ms /    32 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26210.99 ms /   256 tokens (  102.39 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26317.71 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26084.74 ms /   256 tokens (  101.89 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26165.30 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26118.99 ms /   256 tokens (  102.03 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26198.51 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   14543.71 ms /   109 tokens (  133.43 ms per token,     7.49 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   14599.09 ms /   110 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   27991.48 ms /   256 tokens (  109.34 ms per token,     9.15 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   28070.38 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26671.32 ms /   256 tokens (  104.18 ms per token,     9.60 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26750.46 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23675.34 ms /   234 tokens (  101.18 ms per token,     9.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   23772.01 ms /   235 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26072.71 ms /   256 tokens (  101.85 ms per token,     9.82 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26150.95 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25901.61 ms /   256 tokens (  101.18 ms per token,     9.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25981.35 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   13563.53 ms /   140 tokens (   96.88 ms per token,    10.32 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   13624.03 ms /   141 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26214.79 ms /   256 tokens (  102.40 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26295.21 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   17424.57 ms /   146 tokens (  119.35 ms per token,     8.38 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   17485.65 ms /   147 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26231.58 ms /   256 tokens (  102.47 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26333.62 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26125.69 ms /   256 tokens (  102.05 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26204.71 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26366.28 ms /   256 tokens (  102.99 ms per token,     9.71 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26445.51 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26181.65 ms /   256 tokens (  102.27 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26281.47 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   21902.75 ms /   216 tokens (  101.40 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   21976.17 ms /   217 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25867.88 ms /   256 tokens (  101.05 ms per token,     9.90 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25946.09 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25737.74 ms /   256 tokens (  100.54 ms per token,     9.95 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25816.71 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25968.95 ms /   256 tokens (  101.44 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26048.26 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    8412.84 ms /    64 tokens (  131.45 ms per token,     7.61 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    8461.61 ms /    65 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26385.01 ms /   256 tokens (  103.07 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26485.35 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26307.16 ms /   256 tokens (  102.76 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26386.31 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   12582.81 ms /   127 tokens (   99.08 ms per token,    10.09 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   12642.22 ms /   128 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26223.77 ms /   256 tokens (  102.44 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26326.55 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   19127.39 ms /   181 tokens (  105.68 ms per token,     9.46 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   19194.54 ms /   182 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26232.51 ms /   256 tokens (  102.47 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26311.25 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23521.22 ms /   218 tokens (  107.90 ms per token,     9.27 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   23823.49 ms /   219 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26713.21 ms /   256 tokens (  104.35 ms per token,     9.58 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26793.53 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26390.34 ms /   256 tokens (  103.09 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26469.96 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26394.32 ms /   256 tokens (  103.10 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26494.73 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26312.85 ms /   256 tokens (  102.78 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26392.41 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   22522.20 ms /   210 tokens (  107.25 ms per token,     9.32 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   22592.91 ms /   211 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26435.18 ms /   256 tokens (  103.26 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26549.25 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   16971.56 ms /   178 tokens (   95.35 ms per token,    10.49 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   17039.08 ms /   179 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26188.82 ms /   256 tokens (  102.30 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26267.96 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26310.80 ms /   256 tokens (  102.78 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26413.33 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26271.93 ms /   256 tokens (  102.62 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26350.37 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25325.44 ms /   247 tokens (  102.53 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25405.03 ms /   248 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25823.98 ms /   256 tokens (  100.87 ms per token,     9.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25902.58 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25848.77 ms /   256 tokens (  100.97 ms per token,     9.90 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25926.49 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26003.15 ms /   256 tokens (  101.57 ms per token,     9.84 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26107.48 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25996.80 ms /   256 tokens (  101.55 ms per token,     9.85 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26074.68 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25971.19 ms /   256 tokens (  101.45 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26057.60 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25992.59 ms /   256 tokens (  101.53 ms per token,     9.85 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26093.37 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23982.81 ms /   228 tokens (  105.19 ms per token,     9.51 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   24058.39 ms /   229 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   24948.75 ms /   232 tokens (  107.54 ms per token,     9.30 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25023.79 ms /   233 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26412.96 ms /   256 tokens (  103.18 ms per token,     9.69 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26513.46 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26215.14 ms /   256 tokens (  102.40 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26294.57 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   17431.40 ms /   166 tokens (  105.01 ms per token,     9.52 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   17496.04 ms /   167 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    8432.28 ms /    71 tokens (  118.76 ms per token,     8.42 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    8482.33 ms /    72 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26445.39 ms /   256 tokens (  103.30 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26524.25 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26204.62 ms /   256 tokens (  102.36 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26283.75 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    8518.82 ms /    92 tokens (   92.60 ms per token,    10.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    8574.02 ms /    93 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26177.20 ms /   256 tokens (  102.25 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26277.91 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26159.76 ms /   256 tokens (  102.19 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26241.17 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   19873.08 ms /   177 tokens (  112.28 ms per token,     8.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   19939.71 ms /   178 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26264.60 ms /   256 tokens (  102.60 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26364.54 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26348.43 ms /   256 tokens (  102.92 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26428.36 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26265.32 ms /   256 tokens (  102.60 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26345.21 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26173.26 ms /   256 tokens (  102.24 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26253.07 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25673.12 ms /   256 tokens (  100.29 ms per token,     9.97 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25752.28 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25883.88 ms /   256 tokens (  101.11 ms per token,     9.89 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26227.31 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25526.07 ms /   256 tokens (   99.71 ms per token,    10.03 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25605.80 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25680.11 ms /   256 tokens (  100.31 ms per token,     9.97 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25757.98 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25485.89 ms /   256 tokens (   99.55 ms per token,    10.04 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25592.21 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25858.98 ms /   256 tokens (  101.01 ms per token,     9.90 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25938.27 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26193.34 ms /   256 tokens (  102.32 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26273.17 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26006.43 ms /   254 tokens (  102.39 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26086.14 ms /   255 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26000.20 ms /   256 tokens (  101.56 ms per token,     9.85 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26080.54 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26251.51 ms /   256 tokens (  102.54 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26352.40 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25821.17 ms /   256 tokens (  100.86 ms per token,     9.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25901.16 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23361.74 ms /   226 tokens (  103.37 ms per token,     9.67 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   23435.58 ms /   227 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26285.82 ms /   256 tokens (  102.68 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26386.76 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26458.89 ms /   256 tokens (  103.36 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26538.33 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26326.68 ms /   256 tokens (  102.84 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26406.03 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23695.33 ms /   225 tokens (  105.31 ms per token,     9.50 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   23790.37 ms /   226 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26754.28 ms /   256 tokens (  104.51 ms per token,     9.57 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26832.99 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25244.62 ms /   244 tokens (  103.46 ms per token,     9.67 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25322.18 ms /   245 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26227.54 ms /   256 tokens (  102.45 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26306.72 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26255.21 ms /   256 tokens (  102.56 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26334.76 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25628.59 ms /   256 tokens (  100.11 ms per token,     9.99 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25742.92 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25735.21 ms /   256 tokens (  100.53 ms per token,     9.95 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25814.67 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25631.49 ms /   256 tokens (  100.12 ms per token,     9.99 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25709.19 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25424.30 ms /   256 tokens (   99.31 ms per token,    10.07 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25526.52 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25875.07 ms /   256 tokens (  101.07 ms per token,     9.89 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25954.51 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26110.25 ms /   256 tokens (  101.99 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26200.90 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26134.00 ms /   256 tokens (  102.09 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26214.10 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26095.42 ms /   256 tokens (  101.94 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26175.38 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26096.87 ms /   256 tokens (  101.94 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26196.89 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25903.79 ms /   256 tokens (  101.19 ms per token,     9.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25982.60 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26037.10 ms /   256 tokens (  101.71 ms per token,     9.83 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26115.64 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25830.94 ms /   256 tokens (  100.90 ms per token,     9.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25932.44 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26143.46 ms /   256 tokens (  102.12 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26223.07 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26154.45 ms /   256 tokens (  102.17 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26232.97 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26145.46 ms /   256 tokens (  102.13 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26223.82 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26169.46 ms /   256 tokens (  102.22 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26247.67 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26227.96 ms /   256 tokens (  102.45 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26329.05 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26257.00 ms /   256 tokens (  102.57 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26335.04 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26137.46 ms /   256 tokens (  102.10 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26216.40 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   13855.93 ms /   119 tokens (  116.44 ms per token,     8.59 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   13935.06 ms /   120 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25923.97 ms /   256 tokens (  101.27 ms per token,     9.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26003.72 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   21609.41 ms /   218 tokens (   99.13 ms per token,    10.09 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   21683.01 ms /   219 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26174.43 ms /   256 tokens (  102.24 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26275.50 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   15646.59 ms /   139 tokens (  112.57 ms per token,     8.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   15706.54 ms /   140 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26210.27 ms /   256 tokens (  102.38 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26289.62 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26325.90 ms /   256 tokens (  102.84 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26426.12 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   21436.60 ms /   195 tokens (  109.93 ms per token,     9.10 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   21505.75 ms /   196 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26227.73 ms /   256 tokens (  102.45 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26307.03 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26328.26 ms /   256 tokens (  102.84 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26426.96 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25983.01 ms /   256 tokens (  101.50 ms per token,     9.85 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26063.04 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25826.91 ms /   256 tokens (  100.89 ms per token,     9.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25906.79 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   11570.43 ms /   127 tokens (   91.11 ms per token,    10.98 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   11629.22 ms /   128 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26187.48 ms /   256 tokens (  102.29 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26265.83 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26276.47 ms /   256 tokens (  102.64 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26355.90 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26089.52 ms /   256 tokens (  101.91 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26190.37 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26135.06 ms /   256 tokens (  102.09 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26221.37 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26306.56 ms /   256 tokens (  102.76 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26385.35 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   23632.21 ms /   225 tokens (  105.03 ms per token,     9.52 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   23726.98 ms /   226 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26376.79 ms /   256 tokens (  103.03 ms per token,     9.71 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26456.47 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    5863.09 ms /    52 tokens (  112.75 ms per token,     8.87 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    5909.75 ms /    53 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26068.04 ms /   256 tokens (  101.83 ms per token,     9.82 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26146.94 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26296.01 ms /   256 tokens (  102.72 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26373.74 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25948.19 ms /   256 tokens (  101.36 ms per token,     9.87 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26027.42 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    7911.76 ms /    54 tokens (  146.51 ms per token,     6.83 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    7959.34 ms /    55 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25953.99 ms /   256 tokens (  101.38 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26055.77 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25855.67 ms /   256 tokens (  101.00 ms per token,     9.90 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25948.64 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25662.83 ms /   252 tokens (  101.84 ms per token,     9.82 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25741.35 ms /   253 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26180.92 ms /   256 tokens (  102.27 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26282.38 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26246.59 ms /   256 tokens (  102.53 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26327.65 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26262.27 ms /   256 tokens (  102.59 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26599.89 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   22259.55 ms /   217 tokens (  102.58 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   22333.79 ms /   218 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25959.78 ms /   256 tokens (  101.41 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26039.61 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26037.92 ms /   256 tokens (  101.71 ms per token,     9.83 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26139.42 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26159.98 ms /   256 tokens (  102.19 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26241.53 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26278.36 ms /   256 tokens (  102.65 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26357.18 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26306.55 ms /   256 tokens (  102.76 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26417.00 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26481.52 ms /   256 tokens (  103.44 ms per token,     9.67 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26560.90 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26454.14 ms /   256 tokens (  103.34 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26533.92 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26482.24 ms /   256 tokens (  103.45 ms per token,     9.67 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26586.83 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26186.72 ms /   256 tokens (  102.29 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26265.66 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26167.56 ms /   256 tokens (  102.22 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26267.54 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26229.21 ms /   256 tokens (  102.46 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26308.55 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26118.16 ms /   256 tokens (  102.02 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26197.46 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26237.43 ms /   256 tokens (  102.49 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26337.51 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26095.44 ms /   256 tokens (  101.94 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26174.30 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   15087.05 ms /   125 tokens (  120.70 ms per token,     8.29 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   15144.93 ms /   126 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25839.38 ms /   256 tokens (  100.94 ms per token,     9.91 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25941.34 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25789.84 ms /   256 tokens (  100.74 ms per token,     9.93 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25868.57 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26103.02 ms /   256 tokens (  101.96 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26182.05 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25775.60 ms /   256 tokens (  100.69 ms per token,     9.93 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25876.72 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25936.72 ms /   256 tokens (  101.32 ms per token,     9.87 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26017.05 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25677.62 ms /   256 tokens (  100.30 ms per token,     9.97 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25757.26 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25554.15 ms /   256 tokens (   99.82 ms per token,    10.02 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25655.70 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25851.84 ms /   256 tokens (  100.98 ms per token,     9.90 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25945.43 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   28281.19 ms /   256 tokens (  110.47 ms per token,     9.05 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   28399.56 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   32426.65 ms /   256 tokens (  126.67 ms per token,     7.89 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   32506.86 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26291.37 ms /   256 tokens (  102.70 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26371.12 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26301.26 ms /   256 tokens (  102.74 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26402.22 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    8648.92 ms /    90 tokens (   96.10 ms per token,    10.41 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    8701.86 ms /    91 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26756.48 ms /   256 tokens (  104.52 ms per token,     9.57 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26835.61 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26403.66 ms /   256 tokens (  103.14 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26505.62 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26174.09 ms /   256 tokens (  102.24 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26252.77 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26382.47 ms /   256 tokens (  103.06 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26461.08 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   21719.76 ms /   198 tokens (  109.70 ms per token,     9.12 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   22055.66 ms /   199 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26230.80 ms /   256 tokens (  102.46 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26310.93 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26279.24 ms /   256 tokens (  102.65 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26358.12 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26165.61 ms /   256 tokens (  102.21 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26265.37 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26238.63 ms /   256 tokens (  102.49 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26318.13 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26191.06 ms /   256 tokens (  102.31 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26271.33 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26251.05 ms /   256 tokens (  102.54 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26351.32 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26199.31 ms /   256 tokens (  102.34 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26278.68 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =    3415.80 ms /    38 tokens (   89.89 ms per token,    11.12 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =    3461.23 ms /    39 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26120.04 ms /   256 tokens (  102.03 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26220.00 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26235.88 ms /   256 tokens (  102.48 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26314.97 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26203.47 ms /   256 tokens (  102.36 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26282.71 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26298.22 ms /   256 tokens (  102.73 ms per token,     9.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26398.11 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26206.76 ms /   256 tokens (  102.37 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26285.49 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26442.20 ms /   256 tokens (  103.29 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26520.74 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26375.13 ms /   256 tokens (  103.03 ms per token,     9.71 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26476.35 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26295.59 ms /   256 tokens (  102.72 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26375.11 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26155.53 ms /   256 tokens (  102.17 ms per token,     9.79 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26254.59 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26255.74 ms /   256 tokens (  102.56 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26334.62 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25014.13 ms /   239 tokens (  104.66 ms per token,     9.55 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25089.03 ms /   240 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26272.44 ms /   256 tokens (  102.63 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26373.56 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26133.12 ms /   256 tokens (  102.08 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26212.40 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26341.31 ms /   256 tokens (  102.90 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26420.76 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26233.23 ms /   256 tokens (  102.47 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26335.24 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26264.20 ms /   256 tokens (  102.59 ms per token,     9.75 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26342.82 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26198.03 ms /   256 tokens (  102.34 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26277.46 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26344.74 ms /   256 tokens (  102.91 ms per token,     9.72 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26424.43 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26190.28 ms /   256 tokens (  102.31 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26269.87 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26181.84 ms /   256 tokens (  102.27 ms per token,     9.78 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26281.32 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26387.05 ms /   256 tokens (  103.07 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26466.39 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   21992.45 ms /   205 tokens (  107.28 ms per token,     9.32 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   22062.83 ms /   206 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26734.45 ms /   256 tokens (  104.43 ms per token,     9.58 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26835.33 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   17234.60 ms /   170 tokens (  101.38 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   17300.40 ms /   171 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26004.56 ms /   256 tokens (  101.58 ms per token,     9.84 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26092.60 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25934.02 ms /   256 tokens (  101.30 ms per token,     9.87 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26273.95 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25910.70 ms /   256 tokens (  101.21 ms per token,     9.88 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25989.97 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25933.24 ms /   256 tokens (  101.30 ms per token,     9.87 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26011.57 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26038.33 ms /   256 tokens (  101.71 ms per token,     9.83 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26149.70 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   11895.02 ms /    92 tokens (  129.29 ms per token,     7.73 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   11948.63 ms /    93 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26199.99 ms /   256 tokens (  102.34 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26278.57 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26241.71 ms /   256 tokens (  102.51 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26341.43 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26394.23 ms /   256 tokens (  103.10 ms per token,     9.70 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26473.11 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26213.83 ms /   256 tokens (  102.40 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26292.43 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26276.30 ms /   256 tokens (  102.64 ms per token,     9.74 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26376.06 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26355.77 ms /   256 tokens (  102.95 ms per token,     9.71 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26435.40 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26199.66 ms /   256 tokens (  102.34 ms per token,     9.77 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26279.20 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26451.55 ms /   256 tokens (  103.33 ms per token,     9.68 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26530.41 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26218.42 ms /   256 tokens (  102.42 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26297.92 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   12039.64 ms /   126 tokens (   95.55 ms per token,    10.47 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   12097.04 ms /   127 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26114.73 ms /   256 tokens (  102.01 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26216.42 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26071.14 ms /   256 tokens (  101.84 ms per token,     9.82 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26152.70 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26091.38 ms /   256 tokens (  101.92 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26193.43 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25038.16 ms /   247 tokens (  101.37 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25115.03 ms /   248 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26083.53 ms /   256 tokens (  101.89 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26162.79 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26098.43 ms /   256 tokens (  101.95 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26198.14 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26107.44 ms /   256 tokens (  101.98 ms per token,     9.81 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26186.44 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26222.65 ms /   256 tokens (  102.43 ms per token,     9.76 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26301.78 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   19956.98 ms /   180 tokens (  110.87 ms per token,     9.02 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   20046.31 ms /   181 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   17906.79 ms /   166 tokens (  107.87 ms per token,     9.27 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   17971.18 ms /   167 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25793.32 ms /   256 tokens (  100.76 ms per token,     9.93 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25871.28 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25767.53 ms /   256 tokens (  100.65 ms per token,     9.93 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   25868.27 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   17962.26 ms /   182 tokens (   98.69 ms per token,    10.13 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   18029.22 ms /   183 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   25952.66 ms /   256 tokens (  101.38 ms per token,     9.86 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26031.48 ms /   257 tokens\n","\n","llama_print_timings:        load time =   26788.38 ms\n","llama_print_timings:      sample time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings: prompt eval time =   26128.85 ms /   256 tokens (  102.07 ms per token,     9.80 tokens per second)\n","llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:       total time =   26229.60 ms /   257 tokens\n"]}],"source":["# \"\"\"\n","# 런타임 모두 실행 시 DB에 데이터가 중복 저장되는 것을 막기 위해 주석 처리 해놨습니다.\n","# 필요한 코드이니 지우지 말아주세요.\n","# \"\"\"\n","#DB에 텍스트 데이터 추가\n","\n","#꼭 확인!!\n","index_name = index_name\n","\n","db.from_documents(chunks,\n","              embedding=hf,\n","              es_cloud_id=ES_CLOUD_ID,\n","              es_user=ES_USER,\n","              es_password=ES_PASSWORD,\n","              es_api_key=ES_API_KEY,\n","              index_name=index_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8F_EHG60W4KV"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1AMbQHTs5QVesZsCak5naJYL4-yTkmNc-","timestamp":1722420505238}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"034fa144d85841e788c5718dfec065c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1762ddb7291144e998dbd1ed3c00c52b","placeholder":"​","style":"IPY_MODEL_79d909c5afbd42a0a6a7f0ba3568cfc7","value":"tokenizer.json: 100%"}},"08f37f8a9f0143959f0c965b9c192c12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13c7760b6ee3478bbb807af9d24daa09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1762ddb7291144e998dbd1ed3c00c52b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4037abe1fe4aa8b75bc11cb505c554":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e2becfd6e7a444583135c3db89783cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f4c3f16910c4d42ada44a9984dee543":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fd84ff3969941d085e4f5a3d59cde9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_480cbf11fde04f6f94e3dca974979dca","placeholder":"​","style":"IPY_MODEL_7011c6a9fa924c5689fd03f9144f5685","value":" 444/444 [00:00&lt;00:00, 39.7kB/s]"}},"238cf22a9a744240ac3e9ad270ee68c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296fbd2153004fb2910e4858a64691a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f4c3f16910c4d42ada44a9984dee543","max":51106,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e2becfd6e7a444583135c3db89783cb","value":51106}},"2c659e2591e942419a7c026c7fde6dc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d13c432356d42fabfc0c1bfe1cb737c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30bf2d11a4aa41739e6b6509468bcf2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3815dd748a0d46239eab5f67988a398c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd0cf5e997af433bbbe25c2bcc68848b","IPY_MODEL_dcf2b444c8cf4653b75ff160d3e6bb50","IPY_MODEL_1fd84ff3969941d085e4f5a3d59cde9a"],"layout":"IPY_MODEL_bbefff3cbb274e89acfde2be1b3acdad"}},"392e3eaac48444bea7af4ca24ac60a18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a2b3e1241f243a1a521697b71685e75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_034fa144d85841e788c5718dfec065c0","IPY_MODEL_b823462c585d42da9ae802cd26a77712","IPY_MODEL_64f987ab2e66463295ff5b902f9222c2"],"layout":"IPY_MODEL_9c1cd57eaaa74ccc83eab30413e713c6"}},"3d07eaace9404d1bb7abeb529969385b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d158802a6204c1f862366f20640eeb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"480cbf11fde04f6f94e3dca974979dca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a5aad8ac915498e9ec69b142c5a6472":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59814da888914dacab99a7b6c2f3bd6c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63fc1f84511647af934a8fd7f04bc1f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64f987ab2e66463295ff5b902f9222c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59814da888914dacab99a7b6c2f3bd6c","placeholder":"​","style":"IPY_MODEL_672a8952726d42918e6a8d375050f217","value":" 9.09M/9.09M [00:00&lt;00:00, 26.2MB/s]"}},"672a8952726d42918e6a8d375050f217":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"688b3e75396b4a7c84a7966407b8e87c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ad9508fa2fa4085b95c2cca010099aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab5e89ebc4444135923950fac5468b62","IPY_MODEL_ee36a15415484fb3b1e4bec940f92e08","IPY_MODEL_9866d0f8c89f47bcb38206fbb6ae3829"],"layout":"IPY_MODEL_3d07eaace9404d1bb7abeb529969385b"}},"7011c6a9fa924c5689fd03f9144f5685":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79d909c5afbd42a0a6a7f0ba3568cfc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81b3af1f90a543ce9f86926ce9da364b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8749e24a6ec04f15837df3eb16c9b8b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63fc1f84511647af934a8fd7f04bc1f2","placeholder":"​","style":"IPY_MODEL_4a5aad8ac915498e9ec69b142c5a6472","value":" 51.1k/51.1k [00:00&lt;00:00, 1.16MB/s]"}},"9866d0f8c89f47bcb38206fbb6ae3829":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81b3af1f90a543ce9f86926ce9da364b","placeholder":"​","style":"IPY_MODEL_688b3e75396b4a7c84a7966407b8e87c","value":" 4/4 [02:15&lt;00:00, 27.41s/it]"}},"9c1cd57eaaa74ccc83eab30413e713c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa8daaf8b869410f90c7bc6b30d277bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4baa9d7f32f4edeb2810c3f8ca662ec","IPY_MODEL_296fbd2153004fb2910e4858a64691a2","IPY_MODEL_8749e24a6ec04f15837df3eb16c9b8b2"],"layout":"IPY_MODEL_3d158802a6204c1f862366f20640eeb5"}},"ab5e89ebc4444135923950fac5468b62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b4037abe1fe4aa8b75bc11cb505c554","placeholder":"​","style":"IPY_MODEL_b8ea293833a14f8188ab448ce0587dcd","value":"Loading checkpoint shards: 100%"}},"b742f7bc99814e42a1c4729770364ae5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b823462c585d42da9ae802cd26a77712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b90ba20967694c4489633599b8a4d6a1","max":9085671,"min":0,"orientation":"horizontal","style":"IPY_MODEL_392e3eaac48444bea7af4ca24ac60a18","value":9085671}},"b8ea293833a14f8188ab448ce0587dcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b90ba20967694c4489633599b8a4d6a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbefff3cbb274e89acfde2be1b3acdad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcf2b444c8cf4653b75ff160d3e6bb50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13c7760b6ee3478bbb807af9d24daa09","max":444,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c659e2591e942419a7c026c7fde6dc7","value":444}},"e4baa9d7f32f4edeb2810c3f8ca662ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6dce1142b0b435285d74e01c9b159ee","placeholder":"​","style":"IPY_MODEL_30bf2d11a4aa41739e6b6509468bcf2a","value":"tokenizer_config.json: 100%"}},"e6dce1142b0b435285d74e01c9b159ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee36a15415484fb3b1e4bec940f92e08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f37f8a9f0143959f0c965b9c192c12","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b742f7bc99814e42a1c4729770364ae5","value":4}},"fd0cf5e997af433bbbe25c2bcc68848b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_238cf22a9a744240ac3e9ad270ee68c0","placeholder":"​","style":"IPY_MODEL_2d13c432356d42fabfc0c1bfe1cb737c","value":"special_tokens_map.json: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
